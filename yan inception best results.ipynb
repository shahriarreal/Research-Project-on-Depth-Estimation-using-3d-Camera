{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"yan inception best results.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"1gi9Jm3tARMB","colab_type":"code","outputId":"f29ed1bc-c21f-478f-9e63-8e6c54a98f8f","executionInfo":{"status":"ok","timestamp":1568103339657,"user_tz":240,"elapsed":3268,"user":{"displayName":"Shahriar Real","photoUrl":"","userId":"17405112322311802962"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rxDjX4CiATIk","colab_type":"code","outputId":"611cd8af-df9c-433b-d4fe-5ab6336bddb9","executionInfo":{"status":"ok","timestamp":1568103342052,"user_tz":240,"elapsed":2098,"user":{"displayName":"Shahriar Real","photoUrl":"","userId":"17405112322311802962"}},"colab":{"base_uri":"https://localhost:8080/","height":56}},"source":["!ls"],"execution_count":35,"outputs":[{"output_type":"stream","text":["drive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Qayvi12AV9_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"9407971d-55b8-47b4-841d-cd12cbfc397e","executionInfo":{"status":"ok","timestamp":1568104021956,"user_tz":240,"elapsed":143694,"user":{"displayName":"Shahriar Real","photoUrl":"","userId":"17405112322311802962"}}},"source":["# -*- coding: utf-8 -*-\n","# from __future__ import absolute_import\n","# from __future__ import print_function\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import cv2\n","from PIL import Image\n","import csv\n","import keras\n","from keras.models import Sequential, Model\n","from keras.layers import Input, Flatten, Dense, Dropout, Lambda, Conv2D, MaxPooling2D, concatenate\n","from keras.optimizers import RMSprop, adam\n","from keras import backend as K\n","from sklearn.model_selection import train_test_split\n","\n","epochs = 30\n","batch_size = 128\n","\n","def euclidean_distance(vects):\n","    x, y = vects\n","    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n","    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n","\n","\n","def eucl_dist_output_shape(shapes):\n","    shape1, shape2 = shapes\n","    return (shape1[0], 1)\n","\n","\n","def cosine_distance(vests):\n","    x, y = vests\n","    x = K.l2_normalize(x, axis=-1)\n","    y = K.l2_normalize(y, axis=-1)\n","    return -K.mean(x * y, axis=-1, keepdims=True)\n","\n","\n","def cos_dist_output_shape(shapes):\n","    shape1, shape2 = shapes\n","    return (shape1[0], 1)\n","\n","\n","def contrastive_loss(y_true, y_pred):\n","    '''Contrastive loss from Hadsell-et-al.'06\n","    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n","    '''\n","    margin = 1\n","    sqaure_pred = K.square(y_pred)\n","    margin_square = K.square(K.maximum(margin - y_pred, 0))\n","    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)\n","\n","\n","def hinge_loss(y_true, y_pred):\n","    margin = K.constant(0.2)\n","    for i in range(0, batch_size, 2):\n","        s_pos = K.sum(y_pred[i])\n","        s_neg = K.sum(y_pred[i + 1])\n","    return K.maximum(K.constant(0), margin + s_neg - s_pos)\n","\n","\n","def create_pairs(x, digit_indices):\n","    '''Positive and negative pair creation.\n","    Alternates between positive and negative pairs.\n","    '''\n","    pairs = []\n","    labels = []\n","    # print([len(digit_indices[d]) for d in range(num_classes)])\n","    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n","    for d in range(num_classes):\n","        for i in range(n):\n","            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n","            pairs += [[x[z1], x[z2]]]\n","            inc = random.randrange(1, num_classes)\n","            dn = (d + inc) % num_classes\n","            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n","            pairs += [[x[z1], x[z2]]]\n","            labels += [1, 0]\n","    return np.array(pairs), np.array(labels)\n","\n","\n","def create_image_pairs(rows, ref, pos, neg):\n","    '''Positive and negative pair creation.\n","    Alternates between positive and negative pairs.\n","    '''\n","    pairs = []\n","    labels = []\n","    for i in range(rows):\n","        ref_patch, pos_patch = ref[i], pos[i]\n","        pairs += [[ref_patch, pos_patch]]\n","        ref_patch, neg_patch = ref[i], neg[i]\n","        pairs += [[ref_patch, neg_patch]]\n","        labels += [1, 0]\n","    return np.array(pairs), np.array(labels)\n","\n","\n","def create_base_network(input_shape):\n","    '''Base network to be shared (eq. to feature extraction).'''\n","  \n","\n","#     model = Sequential()\n","#     model.add(Conv2D(112, (3, 3), activation='relu', input_shape=input_shape))\n","#     model.add(Conv2D(112, (3, 3), activation='relu', padding='same'))\n","#     model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n","#     model.add(Dropout(0.25))\n","#     model.add(Conv2D(112, (3, 3), activation='relu', padding='same'))\n","#     model.add(Conv2D(112, (3, 3), activation='relu', padding='same'))\n","#     model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n","#     model.add(Dropout(0.25))\n","#     model.add(Conv2D(112, (3, 3), activation='relu', padding='same'))\n","#     model.add(Flatten())\n","#     model.add(Dropout(0.25))\n","#     model.add(Dense(384, activation='relu'))\n","   \n","    \n","#     print(model.summary())\n","#     return model  # Model(input, x)\n","  \n","  \n","  \n","  \n","  \n","    input_img = Input(shape = (11, 11, 1))\n","    tower_1 = Conv2D(64, (1,1), padding='same', activation='elu')(input_img)\n","    tower_1 = Conv2D(64, (3,3), padding='same', activation='elu')(tower_1)\n","    tower_2 = Conv2D(64, (1,1), padding='same', activation='elu')(input_img)\n","    tower_2 = Conv2D(64, (5,5), padding='same', activation='elu')(tower_2)\n","    tower_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)\n","    tower_3 = Conv2D(64, (1,1), padding='same', activation='relu')(tower_3)\n","    output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis = 3)\n","    output = Flatten()(output)\n","#     out    = Dense(10, activation='softmax')(output)\n","    out    = Dense(128, activation='softmax')(output)\n","    \n","   \n","\n","    \n","    \n","    \n","    \n","    model = Model(inputs = input_img, outputs = out)\n","    print(model.summary())\n","    return model\n","\n","\n","def compute_accuracy(y_true, y_pred):\n","    '''Compute classification accuracy with a fixed threshold on distances.\n","    '''\n","    pred = y_pred.ravel() > 0.5\n","    return np.mean(pred == y_true)\n","\n","\n","\n","def accuracy(y_true, y_pred):\n","    #Compute classification accuracy with a fixed threshold on distances.\n","\n","    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n","\n","\n","img_rows, img_cols = 11, 11\n","\n","'''\n","# the data, split between train and test sets\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","print(x_train.shape)\n","print(y_train.shape)\n","print(x_test.shape)\n","print(y_test.shape)\n","'''\n","# big_file = '/content/drive/My Drive/yan/middlebury0-22.csv'\n","big_file = '/content/drive/My Drive/yan/446-451(5).csv'\n","\n","csv_train = []\n","csv_test = []\n","csv_big = []\n","\n","with open(big_file) as csvfile:\n","    csv_reader = csv.reader(csvfile)\n","    for row in csv_reader:\n","        csv_big.append(row)\n","len_threshold = round(len(csv_big) * 0.80)\n","for i in range(len_threshold):\n","    csv_train.append(csv_big[i])\n","for i in range(len_threshold, len(csv_big)):\n","    csv_test.append(csv_big[i])\n","csv_big = np.array(csv_big)\n","csv_train = np.array(csv_train)\n","csv_test = np.array(csv_test)\n","[rows_tr, cols] = csv_train.shape\n","[rows_te, cols] = csv_test.shape\n","print('csv_big.shape', csv_big.shape)\n","print('csv_train.shape', csv_train.shape)\n","print('csv_test.shape', csv_test.shape)\n","\n","ref_patches_train = csv_train[:, 0:121]\n","pos_patches_train = csv_train[:, 121:242]\n","neg_patches_train = csv_train[:, 242:]\n","\n","ref_patches_new_train = np.zeros(shape=(rows_tr, 11, 11))\n","pos_patches_new_train = np.zeros(shape=(rows_tr, 11, 11))\n","neg_patches_new_train = np.zeros(shape=(rows_tr, 11, 11))\n","\n","for i in range(rows_tr):\n","    ref_patches_new_train[i] = ref_patches_train[i].reshape((11, 11))\n","    pos_patches_new_train[i] = pos_patches_train[i].reshape((11, 11))\n","    neg_patches_new_train[i] = neg_patches_train[i].reshape((11, 11))\n","\n","print('ref_patch_trains', ref_patches_new_train.shape)\n","'''\n","for i in range(10):\n","    img_ref = Image.fromarray(ref_patches_new_train[i])\n","    img_pos = Image.fromarray(pos_patches_new_train[i])\n","    img_neg = Image.fromarray(neg_patches_new_train[i])\n","    if img_ref.mode != 'RGB':\n","        img_ref = img_ref.convert('RGB')\n","    if  img_pos.mode != 'RGB':\n","        img_pos = img_pos.convert('RGB')\n","    if img_neg.mode != 'RGB':\n","        img_neg = img_neg.convert('RGB')\n","    name_ref = 'ref'+str(i)+'.png'\n","    name_pos = 'pos'+str(i)+'.png'\n","    name_neg = 'neg'+str(i)+'.png'\n","    img_ref.save(name_ref)\n","    img_pos.save(name_pos)\n","    img_neg.save(name_neg)\n","'''\n","ref_patches_test = csv_test[:, 0:121]\n","pos_patches_test = csv_test[:, 121:242]\n","neg_patches_test = csv_test[:, 242:]\n","\n","ref_patches_new_test = np.zeros(shape=(rows_te, 11, 11))\n","pos_patches_new_test = np.zeros(shape=(rows_te, 11, 11))\n","neg_patches_new_test = np.zeros(shape=(rows_te, 11, 11))\n","\n","print('ref_patch_test', ref_patches_new_test.shape)\n","\n","for i in range(rows_te):\n","    ref_patches_new_test[i] = ref_patches_test[i].reshape((11, 11))\n","    pos_patches_new_test[i] = pos_patches_test[i].reshape((11, 11))\n","    neg_patches_new_test[i] = neg_patches_test[i].reshape((11, 11))\n","'''    \n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)\n","\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","'''\n","# remove mean\n","# data augmentation\n","input_shape = (img_rows, img_cols, 1)\n","ref_patches_new_train = ref_patches_new_train.astype('float32')\n","pos_patches_new_train = pos_patches_new_train.astype('float32')\n","neg_patches_new_train = neg_patches_new_train.astype('float32')\n","ref_patches_new_train /= 255\n","pos_patches_new_train /= 255\n","neg_patches_new_train /= 255\n","\n","ref_patches_new_test = ref_patches_new_test.astype('float32')\n","pos_patches_new_test = pos_patches_new_test.astype('float32')\n","neg_patches_new_test = neg_patches_new_test.astype('float32')\n","ref_patches_new_test /= 255\n","pos_patches_new_test /= 255\n","neg_patches_new_test /= 255\n","\n","tr_pairs, tr_y = create_image_pairs(rows_tr, ref_patches_new_train, pos_patches_new_train, neg_patches_new_train)\n","tr_pairs = np.expand_dims(tr_pairs, axis=-1)\n","x_train, x_valid, y_train, y_valid = train_test_split(tr_pairs, tr_y, test_size = 0.3, shuffle= False)\n","\n","print('tr_pairs shape:', tr_pairs[:, 0].shape)\n","print('tr_y shape:', tr_y.shape)\n","print(tr_y)\n","\n","te_pairs, te_y = create_image_pairs(rows_te, ref_patches_new_test, pos_patches_new_test, neg_patches_new_test)\n","te_pairs = np.expand_dims(te_pairs, axis=-1)\n","print('te_pairs shape:', te_pairs[:, 1].shape)\n","print('te_y shape:', te_y.shape)\n","print(te_y)\n","\n","# network definition\n","base_network = create_base_network(input_shape)\n","\n","input_a = Input(shape=input_shape)\n","input_b = Input(shape=input_shape)\n","\n","# because we re-use the same instance `base_network`,\n","# the weights of the network\n","# will be shared across the two branches\n","processed_a = base_network(input_a)\n","processed_b = base_network(input_b)\n","\n","# distance = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([processed_a, processed_b])\n","concatenate_vector = concatenate([processed_a, processed_b], axis=1)\n","# print('concatenate shape', tf.shape(concatenate_vector))\n","\n","dense1 = Dense(384, name='dense1', activation='relu')(concatenate_vector)\n","dense2 = Dense(384, name='dense2', activation='relu')(dense1)\n","output = Dense(1, name='output_layer', activation='sigmoid')(dense2)\n","\n","# distance = Lambda(euclidean_distance,\n","# output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n","\n","model = Model(inputs=[input_a, input_b], outputs=output)\n","print(model.summary())\n","\n","# train\n","rms = RMSprop()\n","# rms = RMSprop(lr=0.0001, rho=0.9, epsilon=None, decay=0.0)\n","# sgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","model.compile(loss='binary_crossentropy', optimizer=rms, metrics=['accuracy'])\n","\n","print(tr_pairs[:, 0].shape)\n","hist =    model.fit([x_train[:, 0], x_train[:, 1]], y_train,\n","          batch_size=128,\n","          epochs=epochs,\n","          validation_data=([x_valid[:, 0], x_valid[:, 1]], y_valid))\n","\n","# compute final accuracy on training and test sets\n","y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n","tr_acc = compute_accuracy(tr_y, y_pred)\n","y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n","te_acc = compute_accuracy(te_y, y_pred)\n","\n","print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n","print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))\n","\n","\n","\n","\n"],"execution_count":41,"outputs":[{"output_type":"stream","text":["csv_big.shape (26629, 363)\n","csv_train.shape (21303, 363)\n","csv_test.shape (5326, 363)\n","ref_patch_trains (21303, 11, 11)\n","ref_patch_test (5326, 11, 11)\n","tr_pairs shape: (42606, 11, 11, 1)\n","tr_y shape: (42606,)\n","[1 0 1 ... 0 1 0]\n","te_pairs shape: (10652, 11, 11, 1)\n","te_y shape: (10652,)\n","[1 0 1 ... 0 1 0]\n","Model: \"model_49\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_74 (InputLayer)           (None, 11, 11, 1)    0                                            \n","__________________________________________________________________________________________________\n","conv2d_126 (Conv2D)             (None, 11, 11, 64)   128         input_74[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_128 (Conv2D)             (None, 11, 11, 64)   128         input_74[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_26 (MaxPooling2D) (None, 11, 11, 1)    0           input_74[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_127 (Conv2D)             (None, 11, 11, 64)   36928       conv2d_126[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_129 (Conv2D)             (None, 11, 11, 64)   102464      conv2d_128[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_130 (Conv2D)             (None, 11, 11, 64)   128         max_pooling2d_26[0][0]           \n","__________________________________________________________________________________________________\n","concatenate_50 (Concatenate)    (None, 11, 11, 192)  0           conv2d_127[0][0]                 \n","                                                                 conv2d_129[0][0]                 \n","                                                                 conv2d_130[0][0]                 \n","__________________________________________________________________________________________________\n","flatten_26 (Flatten)            (None, 23232)        0           concatenate_50[0][0]             \n","__________________________________________________________________________________________________\n","dense_31 (Dense)                (None, 128)          2973824     flatten_26[0][0]                 \n","==================================================================================================\n","Total params: 3,113,600\n","Trainable params: 3,113,600\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Model: \"model_50\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_75 (InputLayer)           (None, 11, 11, 1)    0                                            \n","__________________________________________________________________________________________________\n","input_76 (InputLayer)           (None, 11, 11, 1)    0                                            \n","__________________________________________________________________________________________________\n","model_49 (Model)                (None, 128)          3113600     input_75[0][0]                   \n","                                                                 input_76[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_51 (Concatenate)    (None, 256)          0           model_49[1][0]                   \n","                                                                 model_49[2][0]                   \n","__________________________________________________________________________________________________\n","dense1 (Dense)                  (None, 384)          98688       concatenate_51[0][0]             \n","__________________________________________________________________________________________________\n","dense2 (Dense)                  (None, 384)          147840      dense1[0][0]                     \n","__________________________________________________________________________________________________\n","output_layer (Dense)            (None, 1)            385         dense2[0][0]                     \n","==================================================================================================\n","Total params: 3,360,513\n","Trainable params: 3,360,513\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","(42606, 11, 11, 1)\n","Train on 29824 samples, validate on 12782 samples\n","Epoch 1/30\n","29824/29824 [==============================] - 9s 289us/step - loss: 0.5785 - acc: 0.6758 - val_loss: 0.4844 - val_acc: 0.7781\n","Epoch 2/30\n","29824/29824 [==============================] - 4s 137us/step - loss: 0.4082 - acc: 0.8256 - val_loss: 0.4117 - val_acc: 0.8341\n","Epoch 3/30\n","29824/29824 [==============================] - 4s 138us/step - loss: 0.3451 - acc: 0.8592 - val_loss: 0.4887 - val_acc: 0.7628\n","Epoch 4/30\n","29824/29824 [==============================] - 4s 138us/step - loss: 0.2838 - acc: 0.8870 - val_loss: 0.2655 - val_acc: 0.9028\n","Epoch 5/30\n","29824/29824 [==============================] - 4s 138us/step - loss: 0.2499 - acc: 0.9035 - val_loss: 0.2657 - val_acc: 0.9013\n","Epoch 6/30\n","29824/29824 [==============================] - 4s 138us/step - loss: 0.2122 - acc: 0.9179 - val_loss: 0.2427 - val_acc: 0.9107\n","Epoch 7/30\n","29824/29824 [==============================] - 4s 139us/step - loss: 0.1970 - acc: 0.9250 - val_loss: 0.2819 - val_acc: 0.8932\n","Epoch 8/30\n","29824/29824 [==============================] - 4s 139us/step - loss: 0.1758 - acc: 0.9322 - val_loss: 0.2207 - val_acc: 0.9243\n","Epoch 9/30\n","29824/29824 [==============================] - 4s 138us/step - loss: 0.1649 - acc: 0.9366 - val_loss: 0.2386 - val_acc: 0.9163\n","Epoch 10/30\n","29824/29824 [==============================] - 4s 138us/step - loss: 0.1664 - acc: 0.9375 - val_loss: 0.2835 - val_acc: 0.9048\n","Epoch 11/30\n","29824/29824 [==============================] - 4s 139us/step - loss: 0.1398 - acc: 0.9482 - val_loss: 0.2183 - val_acc: 0.9266\n","Epoch 12/30\n","29824/29824 [==============================] - 4s 137us/step - loss: 0.1292 - acc: 0.9514 - val_loss: 0.2550 - val_acc: 0.9237\n","Epoch 13/30\n","29824/29824 [==============================] - 4s 141us/step - loss: 0.1232 - acc: 0.9532 - val_loss: 0.2690 - val_acc: 0.9171\n","Epoch 14/30\n","29824/29824 [==============================] - 4s 139us/step - loss: 0.1247 - acc: 0.9542 - val_loss: 0.3071 - val_acc: 0.9126\n","Epoch 15/30\n","29824/29824 [==============================] - 4s 139us/step - loss: 0.1103 - acc: 0.9606 - val_loss: 0.2771 - val_acc: 0.9152\n","Epoch 16/30\n","29824/29824 [==============================] - 4s 138us/step - loss: 0.1016 - acc: 0.9618 - val_loss: 0.2513 - val_acc: 0.9264\n","Epoch 17/30\n","29824/29824 [==============================] - 4s 139us/step - loss: 0.0955 - acc: 0.9644 - val_loss: 0.2369 - val_acc: 0.9352\n","Epoch 18/30\n","29824/29824 [==============================] - 4s 138us/step - loss: 0.0906 - acc: 0.9676 - val_loss: 0.2596 - val_acc: 0.9344\n","Epoch 19/30\n","29824/29824 [==============================] - 4s 138us/step - loss: 0.0879 - acc: 0.9683 - val_loss: 0.2631 - val_acc: 0.9330\n","Epoch 20/30\n","29824/29824 [==============================] - 4s 139us/step - loss: 0.0795 - acc: 0.9713 - val_loss: 0.2842 - val_acc: 0.9332\n","Epoch 21/30\n","29824/29824 [==============================] - 4s 140us/step - loss: 0.0773 - acc: 0.9723 - val_loss: 0.2715 - val_acc: 0.9294\n","Epoch 22/30\n","29824/29824 [==============================] - 4s 138us/step - loss: 0.0756 - acc: 0.9734 - val_loss: 0.2508 - val_acc: 0.9354\n","Epoch 23/30\n","29824/29824 [==============================] - 4s 140us/step - loss: 0.0675 - acc: 0.9757 - val_loss: 0.3109 - val_acc: 0.9314\n","Epoch 24/30\n","29824/29824 [==============================] - 4s 141us/step - loss: 0.0639 - acc: 0.9771 - val_loss: 0.2959 - val_acc: 0.9343\n","Epoch 25/30\n","29824/29824 [==============================] - 4s 139us/step - loss: 0.0626 - acc: 0.9776 - val_loss: 0.2996 - val_acc: 0.9361\n","Epoch 26/30\n","29824/29824 [==============================] - 4s 140us/step - loss: 0.0573 - acc: 0.9807 - val_loss: 0.3332 - val_acc: 0.9337\n","Epoch 27/30\n","29824/29824 [==============================] - 4s 139us/step - loss: 0.0565 - acc: 0.9797 - val_loss: 0.3304 - val_acc: 0.9298\n","Epoch 28/30\n","29824/29824 [==============================] - 4s 139us/step - loss: 0.0553 - acc: 0.9812 - val_loss: 0.3134 - val_acc: 0.9310\n","Epoch 29/30\n","29824/29824 [==============================] - 4s 139us/step - loss: 0.0525 - acc: 0.9818 - val_loss: 0.3029 - val_acc: 0.9327\n","Epoch 30/30\n","29824/29824 [==============================] - 4s 139us/step - loss: 0.0470 - acc: 0.9832 - val_loss: 0.3627 - val_acc: 0.9320\n","* Accuracy on training set: 97.21%\n","* Accuracy on test set: 93.66%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gZJJq2roBWNo","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]}]}